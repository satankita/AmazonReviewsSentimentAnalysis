{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satankita/AmazonReviewsSentimentAnalysis/blob/main/AmazonReviewsSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiXMc4iiy_tK"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGXRLatmtLi5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uIzDLlVpGe0",
        "outputId": "13f5f39a-f973-43bc-9faf-bcfaae19f8bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PAOkKCDtQa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4357ba96-91a1-4aea-e17c-bbc03cb8c3f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive/\", force_remount=True)\n",
        "\n",
        "mypath = \"drive/MyDrive/\"\n",
        "# os.listdir(mypath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VhUX7KdwehV"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = mypath + \"TIS Project/Data/\"\n",
        "\n",
        "AMAZON_DATA_TRAIN = \"train.csv\"\n",
        "AMAZON_DATA_TEST = \"test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UC7XNI3009k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcc223e-0399-4a61-d3b4-19993d652ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "%matplotlib inline\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBt9cIjD1HMt"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    a=[f for f in text if f not in string.punctuation]\n",
        "    a=''.join(a)\n",
        "    b=[w for w in a.split() if w.lower() not in stopwords.words('english')]\n",
        "    return b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lm2v4vQGTXr"
      },
      "source": [
        "# Raw Data Check #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UctQ3ytfGV4t"
      },
      "outputs": [],
      "source": [
        "large_data = pd.read_csv(DATA_DIR + AMAZON_DATA_TRAIN)\n",
        "data = large_data.sample(frac=0.01, random_state=101)\n",
        "data.columns = ['Sentiment', 'Review Title', 'Text']\n",
        "data.drop('Review Title', axis=1, inplace=True)\n",
        "\n",
        "data['Length'] = data['Text'].apply(len)\n",
        "data['Word Count'] = data['Text'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znPQG7f2Gfan",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "82ec5869-379d-4bae-e3c1-933c6ef26034"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Sentiment                                               Text  Length  \\\n",
              "750068           2  These splices are easy to pinch shut, but do n...     300   \n",
              "3084052          2  my prayers answered! a great bra! it is hard t...     113   \n",
              "1782585          1  I ordered this watch from Africa and had it co...     270   \n",
              "1315001          1  Sound quality for Widescreen Dolby 5.1 version...     404   \n",
              "2648609          2  My very first hand of real money Texas Holdem ...     778   \n",
              "\n",
              "         Word Count  \n",
              "750068           55  \n",
              "3084052          23  \n",
              "1782585          55  \n",
              "1315001          74  \n",
              "2648609         148  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c8d86bcc-beb3-4014-aee5-5d60da905c03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "      <th>Length</th>\n",
              "      <th>Word Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>750068</th>\n",
              "      <td>2</td>\n",
              "      <td>These splices are easy to pinch shut, but do n...</td>\n",
              "      <td>300</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3084052</th>\n",
              "      <td>2</td>\n",
              "      <td>my prayers answered! a great bra! it is hard t...</td>\n",
              "      <td>113</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782585</th>\n",
              "      <td>1</td>\n",
              "      <td>I ordered this watch from Africa and had it co...</td>\n",
              "      <td>270</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1315001</th>\n",
              "      <td>1</td>\n",
              "      <td>Sound quality for Widescreen Dolby 5.1 version...</td>\n",
              "      <td>404</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2648609</th>\n",
              "      <td>2</td>\n",
              "      <td>My very first hand of real money Texas Holdem ...</td>\n",
              "      <td>778</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8d86bcc-beb3-4014-aee5-5d60da905c03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8d86bcc-beb3-4014-aee5-5d60da905c03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8d86bcc-beb3-4014-aee5-5d60da905c03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e6fd6a5-ba2f-4d6b-96f2-b1ab208ee03f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e6fd6a5-ba2f-4d6b-96f2-b1ab208ee03f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e6fd6a5-ba2f-4d6b-96f2-b1ab208ee03f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 36000,\n  \"fields\": [\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35997,\n        \"samples\": [\n          \"Crashes my XP Pro system at random times, NOT happy!If this is an issue with XP then Blekin should get them to fix it or make some custom drivers for it.Try talking to Blekin, they will dismiss this issue, but it`s real and will freeze your XP system every 3 to 10 hours.DONT BUY IT UNLESS THEY START TO SUPPORT IT !!!!!!!!!\",\n          \"Built ot last is the copy of in search of excellence.I do not know why he copied it and get away with it.Thanks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 234,\n        \"min\": 31,\n        \"max\": 1001,\n        \"num_unique_values\": 947,\n        \"samples\": [\n          316,\n          999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42,\n        \"min\": 5,\n        \"max\": 203,\n        \"num_unique_values\": 194,\n        \"samples\": [\n          131,\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyKpD3bLGg8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "d3de25fd-0073-4e5c-8cfb-fcca92eb930d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "2    18116\n",
              "1    17884\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "data['Sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z690ETK_JDHt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['Text'],data['Sentiment'], test_size=0.3, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ActGA4rYJkKL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "d81b631a-c352-49b5-8ee2-ddd3d642bdaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "2    12629\n",
              "1    12571\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdM2jhDMKt1-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "2b87a845-0662-498a-f85d-f5e6f90e64cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "2    5487\n",
              "1    5313\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYzJaOgusTIa"
      },
      "source": [
        "# VADER Features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VADER is an existing sentiment analysis model that outputs probabilities of 4 sentiments for each word: Positive, Negative, Neutral and Compound. Positive, Negative, and Neutral range from 0 to 1 scores while Compound takes the aggregate of the previous 3 scores, with 1 being the strong negative sentiment and 1 being the strong positive sentiment. These provide 4 additional predictors to the dataset.\n"
      ],
      "metadata": {
        "id": "MFlJPz860yq5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqCQLISe6kKg"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import hstack\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "\n",
        "#large_data = pd.read_csv(DATA_DIR + AMAZON_DATA_TRAIN)\n",
        "#data = large_data.sample(frac=0.01, random_state=101)\n",
        "#data.columns = ['Sentiment', 'Review Title', 'Text']\n",
        "#data.drop('Review Title', axis=1, inplace=True)\n",
        "\n",
        "#data['Length'] = data['Text'].apply(len)\n",
        "#data['Word Count'] = data['Text'].apply(lambda x: len(x.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NszV0PembdpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b9ee0a-6804-4e3a-a291-6e4bdddd81b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "def get_vader_sentiment(text):\n",
        "    return sia.polarity_scores(text)\n",
        "\n",
        "data['VADER_Sentiment'] = data['Text'].apply(get_vader_sentiment)\n",
        "data['VADER_Positive'] = data['VADER_Sentiment'].apply(lambda x: x['pos'])\n",
        "data['VADER_Neutral'] = data['VADER_Sentiment'].apply(lambda x: x['neu'])\n",
        "data['VADER_Negative'] = data['VADER_Sentiment'].apply(lambda x: x['neg'])\n",
        "data['VADER_Compound'] = data['VADER_Sentiment'].apply(lambda x: x['compound'])\n",
        "data.drop(columns=['VADER_Sentiment'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "#updated vader\n",
        "custom_features = data[['Length', 'Word Count', 'VADER_Positive', 'VADER_Neutral', 'VADER_Negative', 'VADER_Compound']].values\n",
        "combined_features = np.hstack([roberta_features, custom_features])\n",
        "\n",
        "# Train-test split with the new combined feature set\n",
        "x_train, x_test, y_train, y_test = train_test_split(combined_features, data['Sentiment'], test_size=0.3, random_state=101)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF testing - removed for final model\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(\n",
        "#     data[['Text', 'VADER_Positive', 'VADER_Neutral', 'VADER_Negative', 'VADER_Compound']],\n",
        "#     data['Sentiment'],\n",
        "#     test_size=0.3,\n",
        "#     random_state=101\n",
        "# )\n",
        "\n",
        "# cv = CountVectorizer(analyzer=clean)\n",
        "# x_train_text = cv.fit_transform(x_train['Text'])\n",
        "# x_test_text = cv.transform(x_test['Text'])\n",
        "\n",
        "# x_train_vader = x_train[['VADER_Positive', 'VADER_Neutral', 'VADER_Negative', 'VADER_Compound']].values\n",
        "# x_test_vader = x_test[['VADER_Positive', 'VADER_Neutral', 'VADER_Negative', 'VADER_Compound']].values\n",
        "\n",
        "# x_train_combined = hstack([x_train_text, x_train_vader])\n",
        "# x_test_combined = hstack([x_test_text, x_test_vader])\n",
        "\n",
        "# tfidf = TfidfTransformer()\n",
        "# x_train_combined = tfidf.fit_transform(x_train_combined)\n",
        "# x_test_combined = tfidf.transform(x_test_combined)"
      ],
      "metadata": {
        "id": "wxobwOQF05nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjNKFl68LVqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42904633-1460-48db-ecee-f9a5435c18b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750068    [splices, easy, pinch, shut, place, much, pres...\n",
            "Name: Text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "checkCV=data['Text'].head(1).apply(clean)\n",
        "print(checkCV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kff7ZJQmJt6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76533753-23c2-4eed-ec7d-dfec1ec7cbd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25200, 89348), (25200, 4), (25200, 89352))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "x_train_text.shape, x_train_vader.shape, x_train_combined.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine**\n",
        "\n",
        "Support vector machine (SVM) is a supervised machine learning algorithm for classification. It aims to find the optimal hyperplane that best separates data into different classes in a high-dimensional space. In our project we used the LinearSVC function in SkLearn, which uses a linear kernel and is specific for classification. We used the default parameters, which uses L2 penalty and squared-hinge loss. Some key advantages of SVM is that it is good with high-dimensions - which our data has after embedding, its inherent property to be less prone to overfitting and its versatility to work with different pre-processing pipelines (including TF-IDF, bag-of-words, etc).\n"
      ],
      "metadata": {
        "id": "STrJYOdd1pQy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Vq965nsBmc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64461964-375d-46cb-c2a3-9cc4dc63846d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Classification Report ##############\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91      5313\n",
            "           2       0.92      0.91      0.91      5487\n",
            "\n",
            "    accuracy                           0.91     10800\n",
            "   macro avg       0.91      0.91      0.91     10800\n",
            "weighted avg       0.91      0.91      0.91     10800\n",
            "\n",
            "##################################################\n",
            "############# Confusion Matrix ##############\n",
            "[[4856  457]\n",
            " [ 481 5006]]\n",
            "##################################################\n"
          ]
        }
      ],
      "source": [
        "svm = LinearSVC()\n",
        "clf = CalibratedClassifierCV(svm)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_predict = clf.predict(x_test)\n",
        "\n",
        "print(\"############# Classification Report ##############\")\n",
        "print(classification_report(y_test, y_predict))\n",
        "print(\"##################################################\")\n",
        "\n",
        "print(\"############# Confusion Matrix ##############\")\n",
        "print(confusion_matrix(y_test, y_predict))\n",
        "print(\"##################################################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1DVlqnopokf"
      },
      "source": [
        "# BERT Embedding Features\n",
        "\n",
        "Text embeddings were generated using Both BERT-base and RoBERTa. BERT (Bidirectional Encoder Representations from Transformers) is a pretrained model that captures contextual\n",
        "word semantics  in high-dimensional vector space. Text data was tokenized using BertTokenizer,\n",
        "and for each review, the [CLS] token’s representation was extracted as the sentence embedding.\n",
        "For this to work you have to change the runtime type to GPU - commented out as not used in model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r2EWcR2gU2g"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "# import torch\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# from sklearn.svm import LinearSVC\n",
        "# from sklearn.calibration import CalibratedClassifierCV\n",
        "# from scipy.sparse import hstack\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PqaWQeSifmk"
      },
      "outputs": [],
      "source": [
        "# large_data = pd.read_csv(DATA_DIR + AMAZON_DATA_TRAIN)\n",
        "# data = large_data.sample(frac=0.01, random_state=101)\n",
        "# data.columns = ['Sentiment', 'Review Title', 'Text']\n",
        "# data.drop('Review Title', axis=1, inplace=True)\n",
        "\n",
        "# data['Length'] = data['Text'].apply(len)\n",
        "# data['Word Count'] = data['Text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7l7C9Mppmjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd07cb0f-b06d-4bf9-8eaf-6d5b565fe6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Confusion Matrix ##############\n",
            "[[4856  457]\n",
            " [ 481 5006]]\n",
            "##################################################\n"
          ]
        }
      ],
      "source": [
        "# def get_bert_embeddings(texts, batch_size=32):\n",
        "#     bert_model.eval()\n",
        "#     all_embeddings = []\n",
        "\n",
        "#     for i in range(0, len(texts), batch_size):\n",
        "#         batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "#         inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
        "#         inputs = {key: value.to(device) for key, value in inputs.items()}  # Move to GPU if available\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             outputs = bert_model(**inputs)\n",
        "\n",
        "#         cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Move back to CPU\n",
        "#         all_embeddings.append(cls_embeddings)\n",
        "\n",
        "#     return np.vstack(all_embeddings)\n",
        "\n",
        "# texts = data['Text'].tolist()\n",
        "# bert_features = get_bert_embeddings(texts, batch_size=32)\n",
        "\n",
        "# custom_features = data[['Length', 'Word Count']].values\n",
        "\n",
        "# combined_features = np.hstack([bert_features, custom_features])\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(combined_features, data['Sentiment'], test_size=0.3, random_state=101)\n",
        "\n",
        "# svm = LinearSVC()\n",
        "# clf = CalibratedClassifierCV(svm)\n",
        "# clf.fit(x_train, y_train)\n",
        "\n",
        "# y_predict = clf.predict(x_test)\n",
        "\n",
        "# print(\"############# Classification Report ##############\")\n",
        "# print(classification_report(y_test, y_predict))\n",
        "# print(\"##################################################\")\n",
        "\n",
        "# print(\"############# Confusion Matrix ##############\")\n",
        "# print(confusion_matrix(y_test, y_predict))\n",
        "# print(\"##################################################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yquhm2fHyBwf"
      },
      "source": [
        "# RoBERTa Embedding Features\n",
        "\n",
        "RoBERTa is an optimized version of BERT. Like BERT, we tokenized the text with RobertaTokenizer and processed with RobertaModel; the [CLS] tokens were extracted from each review to act as our features. RoBERTa embeddings were shown to outperform BERT embeddings by approximately 5 percentage points, demonstrating their ability to capture greater contextual representations. To augment these embeddings, we used features like text length and word count.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orsqHt6ypyS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fef1805-9a1f-4841-df61-6a03f46d3a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ0XpJbxyI0W",
        "outputId": "ae22ac0f-16e5-4adb-9049-5f2de8360a69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "large_data = pd.read_csv(DATA_DIR + AMAZON_DATA_TRAIN)\n",
        "data = large_data.sample(frac=0.01, random_state=101)\n",
        "data.columns = ['Sentiment', 'Review Title', 'Text']\n",
        "data.drop('Review Title', axis=1, inplace=True)\n",
        "\n",
        "data['Length'] = data['Text'].apply(len)\n",
        "data['Word Count'] = data['Text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = RobertaModel.from_pretrained('roberta-base').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "076cFlXzyLFm",
        "outputId": "92654add-2ae0-4f75-f145-c19ddd2d1e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Classification Report ##############\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91      5313\n",
            "           2       0.92      0.91      0.91      5487\n",
            "\n",
            "    accuracy                           0.91     10800\n",
            "   macro avg       0.91      0.91      0.91     10800\n",
            "weighted avg       0.91      0.91      0.91     10800\n",
            "\n",
            "##################################################\n",
            "############# Confusion Matrix ##############\n",
            "[[4861  452]\n",
            " [ 482 5005]]\n",
            "##################################################\n"
          ]
        }
      ],
      "source": [
        "def get_roberta_embeddings(texts, batch_size=32):\n",
        "    roberta_model.eval()\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "\n",
        "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = roberta_model(**inputs)\n",
        "\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "        all_embeddings.append(cls_embeddings)\n",
        "\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "texts = data['Text'].tolist()\n",
        "roberta_features = get_roberta_embeddings(texts, batch_size=32)\n",
        "\n",
        "custom_features = data[['Length', 'Word Count']].values\n",
        "combined_features = np.hstack([roberta_features, custom_features])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(combined_features, data['Sentiment'], test_size=0.3, random_state=101)\n",
        "\n",
        "svm = LinearSVC()\n",
        "clf = CalibratedClassifierCV(svm)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_predict = clf.predict(x_test)\n",
        "\n",
        "print(\"############# Classification Report ##############\")\n",
        "print(classification_report(y_test, y_predict))\n",
        "print(\"##################################################\")\n",
        "\n",
        "print(\"############# Confusion Matrix ##############\")\n",
        "print(confusion_matrix(y_test, y_predict))\n",
        "print(\"##################################################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost**\n",
        "\n",
        "XGBoost (Extreme Gradient Boosting) is a supervised machine learning algorithm that extends gradient boosting methods for classification. Gradient boosting builds ensembles of weak learners (usually decision trees) in a sequential manner and each new tree attempts to correct the errors of the previous. Gradient refers to the descent, the method of updating model parameters to minimize loss. In addition, XGBoost includes regularization terms to help prevent overfitting when training the model and because it splits the data into decision trees, missing or noisy data can be handled better without relying heavily on pre-processing. In comparison to standard gradient boosting, XGBoost has some key advantages, namely improved scalability, faster training through parallelization, handling of imbalanced data, and built in features for customization of regularization and tree pruning. In our project we used the XGBClassifier function in SkLearn with default parameters and objective = ‘binary:logistic’ which supports 2 class classification.\n",
        "\n"
      ],
      "metadata": {
        "id": "_w5AA4g11zlT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5U_zO2EJkMs",
        "outputId": "e5bde3c5-c39d-42a4-e7e5-cca29ad77d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Classification Report ##############\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.90      5313\n",
            "           1       0.90      0.89      0.90      5487\n",
            "\n",
            "    accuracy                           0.90     10800\n",
            "   macro avg       0.90      0.90      0.90     10800\n",
            "weighted avg       0.90      0.90      0.90     10800\n",
            "\n",
            "##################################################\n",
            "############# Confusion Matrix ##############\n",
            "[[4799  514]\n",
            " [ 600 4887]]\n",
            "##################################################\n"
          ]
        }
      ],
      "source": [
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train_XGBC = le.fit_transform(y_train)\n",
        "y_test_XGBC = le.fit_transform(y_test)\n",
        "\n",
        "\n",
        "XGBC = XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "clf_XGBC = CalibratedClassifierCV(XGBC)\n",
        "clf_XGBC.fit(x_train, y_train_XGBC)\n",
        "\n",
        "y_predict_XGBC = clf_XGBC.predict(x_test)\n",
        "\n",
        "print(\"############# Classification Report ##############\")\n",
        "print(classification_report(y_test_XGBC, y_predict_XGBC))\n",
        "print(\"##################################################\")\n",
        "\n",
        "print(\"############# Confusion Matrix ##############\")\n",
        "print(confusion_matrix(y_test_XGBC, y_predict_XGBC))\n",
        "print(\"##################################################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**\n",
        "\n",
        "Random Forest is a supervised machine learning algorithm for classification that uses multiple decision trees to improve the robustness and accuracy of predictions as opposed to singular decision trees. Random forests are generated using bootstrap aggregation (bagging), the subsampling and training of several decision trees whose predictions are aggregated in the end to produce a final result. Predictors at each level for each subsample are randomly selected to avoid repeated use of the same predictors. Random forest has advantages over decision trees in that it reduces overfitting by averaging the predictions of many decision trees, handles high dimensional data by using subsets of features of each tree, and are generally more accurate. In our project we use the RandomForestClassifier function in SkLearn with default parameters, which sets no limit to the tree depth and uses Gini impurity to measure classification improvement at each split.\n"
      ],
      "metadata": {
        "id": "G1-kHw6A11p6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCV5LNy5Lowk"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# RF = RandomForestClassifier()\n",
        "# clf_RF = CalibratedClassifierCV(RF)\n",
        "# clf_RF.fit(x_train, y_train)\n",
        "\n",
        "# y_predict_RF = clf_RF.predict(x_test)\n",
        "\n",
        "# print(\"############# Classification Report ##############\")\n",
        "# print(classification_report(y_test, y_predict_RF))\n",
        "# print(\"##################################################\")\n",
        "\n",
        "# print(\"############# Confusion Matrix ##############\")\n",
        "# print(confusion_matrix(y_test, y_predict_RF))\n",
        "# print(\"##################################################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Nearest Neighbors**\n",
        "\n",
        "K-Nearest Neighbors (KNN) is a supervised machine learning algorithm for classification that classifies a data point based on the similarity to the majority of the k nearest points. It requires a distance measure and a selection for how many neighbors to make a classification. The advantages of KNN are that it is simple to understand and use, and that it is nonparametric (requires no assumptions of underlying variables). However, it is sensitive to irrelevant features, and is poor in high dimensions. In high dimensional feature spaces, we would need to introduce feature reduction techniques (PCA, etc) to improve the accuracy/effectiveness of the model at the cost of adding pre-processing complexity. In addition, figuring out the correct choice of k can heavily affect the model’s performance, as smaller k values cause the model to be more sensitive to noise and larger k values may dilute the importance of certain features/data. In our project we used the KNeighborsClassification in the SkLearn library with default parameters, which sets k=5, and the distance measure to be Euclidean distance.\n"
      ],
      "metadata": {
        "id": "bg6Qn3Jy16SX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68PfLGvBT0TG"
      },
      "outputs": [],
      "source": [
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# KNN = KNeighborsClassifier()\n",
        "# clf_KNN = CalibratedClassifierCV(KNN)\n",
        "# clf_KNN.fit(x_train, y_train)\n",
        "\n",
        "# y_predict_KNN = clf_KNN.predict(x_test)\n",
        "\n",
        "# print(\"############# Classification Report ##############\")\n",
        "# print(classification_report(y_test, y_predict_KNN))\n",
        "# print(\"##################################################\")\n",
        "\n",
        "# print(\"############# Confusion Matrix ##############\")\n",
        "# print(confusion_matrix(y_test, y_predict_KNN))\n",
        "# print(\"##################################################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Model**"
      ],
      "metadata": {
        "id": "KFjksHsa2roN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "\n",
        "base_models = [\n",
        "    ('svm', clf),      #SVM trained on RoBERTa embeddings + custom features\n",
        "    ('xgb', XGBC)      #XGBoost trained on the same\n",
        "]\n",
        "\n",
        "\n",
        "stacking_model = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "#train on RoBERTa features\n",
        "stacking_model.fit(x_train, y_train)\n",
        "\n",
        "#evaluate the stacked model\n",
        "y_pred_stacked = stacking_model.predict(x_test)\n",
        "\n",
        "print(\"############# Stacked Model Classification Report ##############\")\n",
        "print(classification_report(y_test, y_pred_stacked))\n",
        "\n",
        "print(\"############# Stacked Model Confusion Matrix ##############\")\n",
        "print(confusion_matrix(y_test, y_pred_stacked))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXrgSFlOKHVW",
        "outputId": "a4bd2882-246a-4850-cd8e-bc0ad9082ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "############# Stacked Model Classification Report ##############\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91      5313\n",
            "           2       0.92      0.91      0.91      5487\n",
            "\n",
            "    accuracy                           0.91     10800\n",
            "   macro avg       0.91      0.91      0.91     10800\n",
            "weighted avg       0.91      0.91      0.91     10800\n",
            "\n",
            "############# Stacked Model Confusion Matrix ##############\n",
            "[[4851  462]\n",
            " [ 476 5011]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}